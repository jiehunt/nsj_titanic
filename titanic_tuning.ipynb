{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict survival on the Titanic\n",
    "\n",
    "\n",
    "## Import the Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train=pd.read_csv('./input/train.csv',sep=',')\n",
    "df_test=pd.read_csv('./input/test.csv',sep=',')\n",
    "df_data = df_train.append(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the data without preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember train_baseline.py in the first time we use to predict survival.\n",
    "\n",
    "The auc score will around about 0.78x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.select_dtypes(include=['float64', 'int64'])\n",
    "test  = df_test.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "target = ['Survived']\n",
    "x_train = train.drop(target, axis=1)\n",
    "y_train = train['Survived']\n",
    "\n",
    "X_train,X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size=0.1,random_state=2018)\n",
    "\n",
    "dtrain = lgb.Dataset(X_train, label=Y_train)\n",
    "\n",
    "myparams = {\n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'},\n",
    "    'learning_rate': 0.05,\n",
    "  }\n",
    "\n",
    "model = lgb.train(params=myparams, train_set=dtrain)\n",
    "\n",
    "my_pred = model.predict(X_valid)\n",
    "\n",
    "auc_score = roc_auc_score(Y_valid, my_pred)\n",
    "print (auc_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Do some Data preprocessing and get higher auc score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Data Preprocessing, we usully do something like:\n",
    "- deal with outlier\n",
    "- categorical variable encoding.(One-Hot Encoding)\n",
    "- text data embedding.\n",
    "    \n",
    "IN Feature Engineering, we usully do something like:\n",
    "- Feature Extraction(Create some new feature)\n",
    "- Feature Selection(by feature correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the na values in Fare based on embarked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embarked = ['S', 'C', 'Q']\n",
    "for port in embarked:\n",
    "    fare_to_impute = df_data.groupby('Embarked')['Fare'].median()[embarked.index(port)]\n",
    "    df_data.loc[(df_data['Fare'].isnull()) & (df_data['Embarked'] == port), 'Fare'] = fare_to_impute\n",
    "# Fare in df_train and df_test:\n",
    "df_train[\"Fare\"] = df_data['Fare'][:891]\n",
    "df_test[\"Fare\"] = df_data['Fare'][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in missing Fare value in training set based on mean fare for that Pclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(len(df_train[\"Fare\"])):\n",
    "    if pd.isnull(df_train[\"Fare\"][x]):\n",
    "        pclass = df_train[\"Pclass\"][x] #Pclass = 3\n",
    "        df_train[\"Fare\"][x] = round(df_train[df_train[\"Pclass\"] == pclass][\"Fare\"].mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in missing Fare value in test set based on mean fare for that Pclass         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(len(df_test[\"Fare\"])):\n",
    "    if pd.isnull(df_test[\"Fare\"][x]):\n",
    "        pclass = df_test[\"Pclass\"][x] #Pclass = 3\n",
    "        df_test[\"Fare\"][x] = round(df_test[df_test[\"Pclass\"] == pclass][\"Fare\"].mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Fare values into groups of numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data[\"FareBand\"] = pd.qcut(df_data['Fare'], 4, labels = [1, 2, 3, 4]).astype('int')\n",
    "df_train[\"FareBand\"] = pd.qcut(df_train['Fare'], 4, labels = [1, 2, 3, 4]).astype('int')\n",
    "df_test[\"FareBand\"] = pd.qcut(df_test['Fare'], 4, labels = [1, 2, 3, 4]).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map each Embarked value to a numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n",
    "df_data[\"Embarked\"] = df_data[\"Embarked\"].map(embarked_mapping)\n",
    "# split Embanked into df_train and df_test:\n",
    "df_train[\"Embarked\"] = df_data[\"Embarked\"][:891]\n",
    "df_test[\"Embarked\"] = df_data[\"Embarked\"][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the na values in Embanked based on fareband data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fareband = [1,2,3,4]\n",
    "for fare in fareband:\n",
    "    embark_to_impute = df_data.groupby('FareBand')['Embarked'].median()[fare]\n",
    "    df_data.loc[(df_data['Embarked'].isnull()) & (df_data['FareBand'] == fare), 'Embarked'] = embark_to_impute\n",
    "# Fare in df_train and df_test:\n",
    "df_train[\"Embarked\"] = df_data['Embarked'][:891]\n",
    "df_test[\"Embarked\"] = df_data['Embarked'][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert categories to Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(df_train[['Sex']], prefix_sep='_') #Gender\n",
    "df_train = pd.concat([df_train, dummies], axis=1) \n",
    "testdummies=pd.get_dummies(df_test[['Sex']], prefix_sep='_') #Gender\n",
    "df_test = pd.concat([df_test, testdummies], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map each Gendre value to a numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_mapping = {\"female\": 0, \"male\": 1}\n",
    "df_data[\"Sex\"] = df_data['Sex'].map(gender_mapping)\n",
    "df_data[\"Sex\"]=df_data[\"Sex\"].astype('int')\n",
    "\n",
    "# Family_Survival in TRAIN_DF and TEST_DF:\n",
    "df_train[\"Sex\"] = df_data[\"Sex\"][:891]\n",
    "df_test[\"Sex\"] = df_data[\"Sex\"][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_data[\"Title\"] = df_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "#Unify common titles. \n",
    "df_data[\"Title\"] = df_data[\"Title\"].replace('Mlle', 'Miss')\n",
    "df_data[\"Title\"] = df_data[\"Title\"].replace('Master', 'Master')\n",
    "df_data[\"Title\"] = df_data[\"Title\"].replace(['Mme', 'Dona', 'Ms'], 'Mrs')\n",
    "df_data[\"Title\"] = df_data[\"Title\"].replace(['Jonkheer','Don'],'Mr')\n",
    "df_data[\"Title\"] = df_data[\"Title\"].replace(['Capt','Major', 'Col','Rev','Dr'], 'Millitary')\n",
    "df_data[\"Title\"] = df_data[\"Title\"].replace(['Lady', 'Countess','Sir'], 'Honor')\n",
    "\n",
    "# Age in df_train and df_test:\n",
    "df_train[\"Title\"] = df_data['Title'][:891]\n",
    "df_test[\"Title\"] = df_data['Title'][891:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Title categories to Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titledummies=pd.get_dummies(df_train[['Title']], prefix_sep='_') #Title\n",
    "df_train = pd.concat([df_train, titledummies], axis=1) \n",
    "ttitledummies=pd.get_dummies(df_test[['Title']], prefix_sep='_') #Title\n",
    "df_test = pd.concat([df_test, ttitledummies], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Millitary\": 5, \"Honor\": 6}\n",
    "df_data[\"TitleCat\"] = df_data['Title'].map(title_mapping)\n",
    "df_data[\"TitleCat\"] = df_data[\"TitleCat\"].astype(int)\n",
    "df_train[\"TitleCat\"] = df_data[\"TitleCat\"][:891]\n",
    "df_test[\"TitleCat\"] = df_data[\"TitleCat\"][891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = ['Master', 'Miss', 'Mr', 'Mrs', 'Millitary','Honor']\n",
    "for title in titles:\n",
    "    age_to_impute = df_data.groupby('Title')['Age'].median()[title]\n",
    "    df_data.loc[(df_data['Age'].isnull()) & (df_data['Title'] == title), 'Age'] = age_to_impute\n",
    "# Age in df_train and df_test:\n",
    "df_train[\"Age\"] = df_data['Age'][:891]\n",
    "df_test[\"Age\"] = df_data['Age'][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise Age Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\n",
    "axis1.set_title('Training Age values - Titanic')\n",
    "axis2.set_title('Test Age values - Titanic')\n",
    "\n",
    "# plot original Age values\n",
    "df_train['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n",
    "        \n",
    "# plot new Age Values\n",
    "df_test['Age'].hist(bins=70, ax=axis2)\n",
    "\n",
    "# peaks for survived/not survived passengers by their age\n",
    "facet = sns.FacetGrid(df_train, hue=\"Survived\",palette = 'seismic',aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, df_train['Age'].max()))\n",
    "facet.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the trend of survived-age above. So, what is the story?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train[\"Alone\"] = np.where(df_train['SibSp'] + df_train['Parch'] + 1 == 1, 1,0) # People travelling alone\n",
    "df_test[\"Alone\"] = np.where(df_test['SibSp'] + df_test['Parch'] + 1 == 1, 1,0) # People travelling alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train[\"Family Size\"] = (df_train['SibSp'] + df_train['Parch'] + 1)\n",
    "df_test[\"Family Size\"] = df_test['SibSp'] + df_test['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check if cabin inf exists\n",
    "df_data[\"HadCabin\"] = (df_data[\"Cabin\"].notnull().astype('int'))\n",
    "# split Embanked into df_train and df_test:\n",
    "df_train[\"HadCabin\"] = df_data[\"HadCabin\"][:891]\n",
    "df_test[\"HadCabin\"] = df_data[\"HadCabin\"][891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Deck\n",
    "df_data[\"Deck\"] = df_data.Cabin.str.extract('([A-Za-z])', expand=False)\n",
    "df_data[\"Deck\"] = df_data[\"Deck\"].fillna(\"N\")\n",
    "# Map Deck\n",
    "deck_mapping = {\"N\":0,\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5}\n",
    "df_data['Deck'] = df_data['Deck'].map(deck_mapping)\n",
    "#Split to training and test\n",
    "df_train[\"Deck\"] = df_data[\"Deck\"][:891]\n",
    "df_test[\"Deck\"] = df_data[\"Deck\"][891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we did some data preprocessing and feature engineering.\n",
    "\n",
    "Let's trian this data again, and see how is the auc score working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-evaluate with new features\n",
    "NUMERIC_COLUMNS=['Alone','Family Size','Sex','Pclass','Fare','FareBand','Age','TitleCat','Embarked'] #72\n",
    "ORIGINAL_NUMERIC_COLUMNS=['Pclass','Age','SibSp','Parch','Sex_female','Sex_male','Title_Master', 'Title_Miss','Title_Mr', 'Title_Mrs', 'Title_Millitary','Embarked'] #83\n",
    "REVISED_NUMERIC_COLUMNS=['Pclass','Age','SibSp','Parch','Alone','Sex_female','Sex_male','Title_Master', 'Title_Miss','Title_Mr', 'Title_Mrs', 'Title_Millitary','Embarked'] #84\n",
    "\n",
    "# create test and training data\n",
    "data_to_train = df_train[REVISED_NUMERIC_COLUMNS].fillna(-1000)\n",
    "y=df_train['Survived']\n",
    "X=data_to_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=2018)\n",
    "\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "myparams = {\n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'}\n",
    "}\n",
    "\n",
    "model = lgb.train(params=myparams, train_set=dtrain)\n",
    "\n",
    "my_pred = model.predict(X_test)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, my_pred)\n",
    "print (auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Parameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set params\n",
    "# Scores ~0.784 (without tuning and early stopping)    \n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective': 'binary', \n",
    "          'num_leaves': 12, \n",
    "          'learning_rate': 0.05, \n",
    "          'metric' : 'auc'}\n",
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005, 0.01,0.05,0.1,0.3],\n",
    "    'num_leaves': [3,4,6,8,12,16],\n",
    "    }\n",
    "\n",
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "mdl = lgb.LGBMClassifier()\n",
    "\n",
    "# To view the default model params:\n",
    "mdl.get_params().keys()\n",
    "\n",
    "# Create the grid\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=4, n_jobs=-1)\n",
    "\n",
    "# Run the grid\n",
    "grid.fit(X_train, y_train,verbose=3)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "# Using parameters already set above, replace in the best from the grid search\n",
    "params['learning_rate'] = grid.best_params_['learning_rate'] \n",
    "params['num_leaves'] = grid.best_params_['num_leaves']\n",
    "\n",
    "print('Fitting with params: ')\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "\n",
    "model = lgb.train(params=params, train_set=dtrain)\n",
    "\n",
    "my_pred = model.predict(X_test)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, my_pred)\n",
    "print (auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
